{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded and preprocessed!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Convert class vectors to binary class matrices (one-hot encoding)\n",
    "train_labels = to_categorical(train_labels, 10)\n",
    "test_labels = to_categorical(test_labels, 10)\n",
    "\n",
    "print(\"Dataset loaded and preprocessed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN model architecture created!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Initialize the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layer with 32 filters, a kernel size of 3x3, activation function 'relu', and input shape\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "\n",
    "# Add a second convolutional layer with 64 filters\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Add a max pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add Dropout to prevent overfitting\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Add Flatten layer to flatten the output for the dense layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a dense layer with 512 units and 'relu' activation\n",
    "model.add(Dense(512, activation='relu'))\n",
    "\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Add the output layer with 10 units (for the 10 classes) and 'softmax' activation\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(\"CNN model architecture created!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 1.3913 - accuracy: 0.5004 - val_loss: 1.0417 - val_accuracy: 0.6424\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.0353 - accuracy: 0.6333 - val_loss: 0.9431 - val_accuracy: 0.6711\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.8792 - accuracy: 0.6923 - val_loss: 0.8653 - val_accuracy: 0.6989\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.7631 - accuracy: 0.7331 - val_loss: 0.8539 - val_accuracy: 0.7025\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.6557 - accuracy: 0.7704 - val_loss: 0.8148 - val_accuracy: 0.7193\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.5761 - accuracy: 0.7977 - val_loss: 0.8677 - val_accuracy: 0.7081\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.4960 - accuracy: 0.8237 - val_loss: 0.8913 - val_accuracy: 0.7097\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.4424 - accuracy: 0.8426 - val_loss: 0.8414 - val_accuracy: 0.7259\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 0.3983 - accuracy: 0.8601 - val_loss: 0.9326 - val_accuracy: 0.7141\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 0.3595 - accuracy: 0.8719 - val_loss: 0.9201 - val_accuracy: 0.7295\n",
      "Model training completed!\n"
     ]
    }
   ],
   "source": [
    "# Set number of epochs and batch size\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels, epochs=epochs, batch_size=batch_size, validation_data=(test_images, test_labels))\n",
    "\n",
    "print(\"Model training completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 9ms/step - loss: 0.7958 - accuracy: 0.7271\n",
      "Test Accuracy: 72.71%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 53s 33ms/step - loss: 1.1335 - accuracy: 0.6097 - val_loss: 0.9079 - val_accuracy: 0.6912\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 57s 37ms/step - loss: 1.0607 - accuracy: 0.6318 - val_loss: 0.8396 - val_accuracy: 0.7142\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 58s 37ms/step - loss: 1.0182 - accuracy: 0.6455 - val_loss: 0.9266 - val_accuracy: 0.6788\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 57s 36ms/step - loss: 0.9933 - accuracy: 0.6548 - val_loss: 0.8730 - val_accuracy: 0.6986\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.9738 - accuracy: 0.6618 - val_loss: 0.8507 - val_accuracy: 0.7098\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 58s 37ms/step - loss: 0.9622 - accuracy: 0.6652 - val_loss: 0.8364 - val_accuracy: 0.7119\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.9373 - accuracy: 0.6715 - val_loss: 0.8665 - val_accuracy: 0.7062\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.9328 - accuracy: 0.6788 - val_loss: 0.8972 - val_accuracy: 0.6996\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.9169 - accuracy: 0.6806 - val_loss: 0.8283 - val_accuracy: 0.7201\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.9082 - accuracy: 0.6850 - val_loss: 0.7958 - val_accuracy: 0.7271\n",
      "Model training with data augmentation completed!\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Fit the data augmentation generator to the training data\n",
    "datagen.fit(train_images)\n",
    "\n",
    "# Train the model with augmented data\n",
    "history = model.fit(datagen.flow(train_images, train_labels, batch_size=batch_size),\n",
    "                    epochs=epochs, validation_data=(test_images, test_labels))\n",
    "\n",
    "print(\"Model training with data augmentation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 8ms/step - loss: 0.7958 - accuracy: 0.7271\n",
      "Optimized Test Accuracy: 72.71%\n"
     ]
    }
   ],
   "source": [
    "# Re-evaluate the model on the test dataset after optimization\n",
    "optimized_test_loss, optimized_test_accuracy = model.evaluate(test_images, test_labels)\n",
    "\n",
    "print(f\"Optimized Test Accuracy: {optimized_test_accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('cifar10_classification_model.h5')\n",
    "\n",
    "print(\"Model saved successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
